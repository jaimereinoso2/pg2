{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kstgk2Ow9mme"
      },
      "source": [
        "\n",
        "\n",
        "### Generación de Modelos Predictivos\n",
        "\n",
        "Este notebook se encarga de generar modelos predictivos.  Se puede correr en Google Colab o en el iMac.\n",
        "\n",
        "Para usarlo en Google Colab, usar tipo_a_usar='GPU'\n",
        "Para usarlo en el imac, usar tipo_a_usar='CPU'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z4cDU5C_93sB"
      },
      "outputs": [],
      "source": [
        "tipo_a_usar='CPU'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VvG4qBj15JbK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-ZRjd8R5ycg",
        "outputId": "60a4e1d6-7261-4d0f-c60e-f00968f47a9a"
      },
      "outputs": [],
      "source": [
        "if tipo_a_usar =='GPU':\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS7BpOnV-fR1"
      },
      "source": [
        "Los datos de origen es el mismo sea desde Google Colab o desde el iMac.  La diferencia es que el primero usar referencia a Google Drive y el otro acceso directo desde el sistema operativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G9ljov6i5Vza"
      },
      "outputs": [],
      "source": [
        "if tipo_a_usar =='GPU':\n",
        "  dfbase = pd.read_pickle('/content/drive/MyDrive//Innovaciones Tecnológicas Aplicadas/Universidad Autónoma de Occidente/GoogleColab/checkPoints/DATOS_LIMPIOS.pkl')\n",
        "\n",
        "if tipo_a_usar == 'CPU':\n",
        "  dfbase = pd.read_pickle('checkpoints/DATOS_LIMPIOS.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = dfbase.copy()\n",
        "df = df[df['LABEL']!=-1]\n",
        "\n",
        "X = df.drop('LABEL', axis=1)  # Reemplaza 'target_column' con el nombre de tu columna objetivo\n",
        "y = df['LABEL']  # Reemplaza 'target_column' con el nombre de tu columna objetivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculamos correlación de variables independientes\n",
        "corr_matrix = X.corr()\n",
        "\n",
        "import numpy as np\n",
        "mitad_inferior = np.tril(corr_matrix, k=-1)\n",
        "mitad_inferior = pd.DataFrame(mitad_inferior, columns=corr_matrix.columns, index=corr_matrix.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "umbral: 0.1 1953 1357 596\n",
            "!!!!!!! UMBRAL: 0.1\n",
            "Mejores hiperparámetros encontrados:\n",
            "{'C': 10, 'degree': 2, 'kernel': 'linear'}\n",
            "Mejor puntuación en entrenamiento:\n",
            "0.7488658739200182\n",
            "Precisión (Accuracy) en prueba: 0.7513227513227513\n",
            "ROC-AUC en prueba: 0.5916562016296253\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "lista_umbral = [0.1]\n",
        "\n",
        "for umbral in lista_umbral:\n",
        "    j = 0\n",
        "    variables_eliminar = set()\n",
        "    for c in mitad_inferior.columns:\n",
        "        i = 0\n",
        "        for v in mitad_inferior[c]:\n",
        "            if v > umbral:\n",
        "                variables_eliminar.add(mitad_inferior.index[i])           \n",
        "            i = i + 1\n",
        "        j = j + 1\n",
        "    print('umbral:', \n",
        "          umbral, len(mitad_inferior.columns), \n",
        "          len(variables_eliminar),\n",
        "          len(mitad_inferior.columns) - len(variables_eliminar))\n",
        "    \n",
        "    Xnew = X.drop(list(variables_eliminar), axis=1)\n",
        "\n",
        "    # Separar los datos en conjuntos de entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(Xnew, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Definir los hiperparámetros a ajustar y sus posibles valores para SVM\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'degree': [2, 3, 4],\n",
        "    }\n",
        "\n",
        "    # Crear el modelo SVM\n",
        "    modelo_svm = SVC(random_state=42, probability=True)\n",
        "\n",
        "    # Realizar la búsqueda en cuadrícula con validación cruzada en el conjunto de entrenamiento\n",
        "    grid_search = GridSearchCV(estimator=modelo_svm, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print('!!!!!!! UMBRAL:', umbral)\n",
        "\n",
        "    # Mostrar los mejores hiperparámetros y la mejor puntuación en el conjunto de entrenamiento\n",
        "    print(\"Mejores hiperparámetros encontrados:\")\n",
        "    print(grid_search.best_params_)\n",
        "    print(\"Mejor puntuación en entrenamiento:\")\n",
        "    print(grid_search.best_score_)\n",
        "\n",
        "    # Obtener el modelo con los mejores hiperparámetros\n",
        "    mejor_modelo_svm = grid_search.best_estimator_\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de prueba\n",
        "    y_pred = mejor_modelo_svm.predict(X_test)\n",
        "    accuracy_test = accuracy_score(y_test, y_pred)\n",
        "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Mostrar los resultados en el conjunto de prueba\n",
        "    print(\"Precisión (Accuracy) en prueba:\", accuracy_test)\n",
        "    print(\"ROC-AUC en prueba:\", roc_auc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6611, 596)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xnew.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
